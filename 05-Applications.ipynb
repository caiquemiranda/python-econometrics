{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time series"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date and time data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-02 08:44:11.462916\n",
      "2\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# Datetime creation\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "print(now)\n",
    "## datetime.datetime(2022, 2, 14, 0, 36, 9, 153276)\n",
    "\n",
    "print(now.day)\n",
    "## 14\n",
    "\n",
    "print(now.hour)\n",
    "## 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The exam will be on the 2020-12-09\n"
     ]
    }
   ],
   "source": [
    "# Datetime representation\n",
    "\n",
    "holiday = datetime(2020, 12, 24, 8, 30)\n",
    "\n",
    "holiday\n",
    "## datetime.datetime(2020, 12, 24, 8, 30)\n",
    "\n",
    "exam = datetime(2020, 12, 9, 10)\n",
    "\n",
    "print(\"The exam will be on the \" + \"{:%Y-%m-%d}\".format(exam))\n",
    "## The exam will be on the 2020-12-09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-754 days, 1:15:48.537084\n",
      "The exam will take place in -754 days.\n",
      "2023-01-02 08:44:11.462916\n",
      "2023-01-12 08:46:11.462916\n"
     ]
    }
   ],
   "source": [
    "# Datetime difference\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "delta = exam - now\n",
    "\n",
    "print(delta)\n",
    "## datetime.timedelta(days=-432, seconds=33830, microseconds=846724)\n",
    "\n",
    "print(\"The exam will take place in \" + str(delta.days) + \" days.\")\n",
    "## The exam will take place in -432 days.\n",
    "\n",
    "print(now)\n",
    "## datetime.datetime(2022, 2, 14, 0, 36, 9, 153276)\n",
    "\n",
    "print(now + timedelta(10, 120))\n",
    "## datetime.datetime(2022, 2, 24, 0, 38, 9, 153276)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert string and datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-12 00:00:00\n",
      "German date format: 12.04.2020\n",
      "2020-05-05 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Convert Datetime\n",
    "\n",
    "stamp = datetime(2020, 4, 12)\n",
    "\n",
    "print(stamp)\n",
    "## datetime.datetime(2020, 4, 12, 0, 0)\n",
    "\n",
    "print(\"German date format: \" + stamp.strftime(\"%d.%m.%Y\"))\n",
    "## German date format: 12.04.2020\n",
    "\n",
    "val = \"2020-5-5\"\n",
    "d = datetime.strptime(val, \"%Y-%m-%d\")\n",
    "\n",
    "print(d)\n",
    "## datetime.datetime(2020, 5, 5, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-01-31 00:00:00\n",
      "Today is Monday and we are in week 01 of the year 2023.\n",
      "Mon Jan  2 08:44:11 2023\n"
     ]
    }
   ],
   "source": [
    "# Converting examples\n",
    "\n",
    "val = \"31.01.2012\"\n",
    "d = datetime.strptime(val, \"%d.%m.%Y\")\n",
    "\n",
    "print(d)\n",
    "## datetime.datetime(2012, 1, 31, 0, 0)\n",
    "\n",
    "print(now.strftime(\"Today is %A and we are in week %W of the year %Y.\"))\n",
    "## 'Today is Monday and we are in week 07 of the year 2022.'\n",
    "\n",
    "print(now.strftime(\"%c\"))\n",
    "## 'Mon Feb 14 00:36:09 2022'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview: Datetime formats\n",
    "\n",
    "|Type|Description|\n",
    "|--|--|\n",
    "|%Y |4-digit year|\n",
    "|%m |2-digit month [01, 12]|\n",
    "|%d |2-digit day [01, 31]|\n",
    "|%H |Hour (24-hour clock) [00, 23]|\n",
    "|%I |Hour (12-hour clock) [01, 12]|\n",
    "|%M |2-digit minute [00, 59]|\n",
    "|%S |Second [00, 61]|\n",
    "|%W |Week number of the year [00, 53]|\n",
    "|%F |Shortcut for %Y-%m-%d|\n",
    "|%a |Abbreviated weekday name|\n",
    "|%A |Full weekday name|\n",
    "|%b |Abbreviated month name|\n",
    "|%B |Full month name|\n",
    "|%c |Full date and time|\n",
    "|%x |Locale-appropriate formatted date|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating date ranges with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2020-01-31', '2020-02-29'], dtype='datetime64[ns]', freq='M')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Date ranges\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "index = pd.date_range(\"2020-01-01\", now)\n",
    "\n",
    "index[0:2]\n",
    "index[15:16]\n",
    "\n",
    "index = pd.date_range(\"2020-01-01\", now, freq=\"M\")\n",
    "\n",
    "index[0:2]\n",
    "## DatetimeIndex(['2020-01-01', '2...ype='datetime64[ns]', freq='D')\n",
    "## DatetimeIndex(['2020-01-16'], dtype='datetime64[ns]', freq='D')\n",
    "## DatetimeIndex(['2020-01-31', '2...ype='datetime64[ns]', freq='M')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview: Time series frequencies\n",
    "\n",
    "|Alias |Offset type|\n",
    "|--|--|\n",
    "|D |Day|\n",
    "|B |Business day|\n",
    "|H |Hour|\n",
    "|T |Minute|\n",
    "|S |Second|\n",
    "|M |Month end|\n",
    "|BM |Business month end|\n",
    "|Q-JAN, Q-FEB, ... |Quarter end|\n",
    "|A-JAN, A-FEB, ... |Year end|\n",
    "|AS-JAN, AS-FEB, ... |Year begin|\n",
    "|BA-JAN, BA-FEB, ... |Business year end|\n",
    "|BAS-JAN, BAS-FEB, ... |Business year begin|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resample date ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample date ranges\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "start = datetime(2016, 1, 1)\n",
    "\n",
    "ind = pd.date_range(start, now)\n",
    "\n",
    "numbers = np.arange((now - start).days + 1)\n",
    "\n",
    "df = pd.DataFrame(numbers, index=ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "2016-01-01  0\n",
       "2016-01-02  1\n",
       "2016-01-03  2\n",
       "2016-01-04  3\n",
       "2016-01-05  4"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "## 0\n",
    "## 2016-01-01 0\n",
    "## 2016-01-02 1\n",
    "## 2016-01-03 2\n",
    "## 2016-01-04 3\n",
    "## 2016-01-05 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-29</th>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-29</th>\n",
       "      <td>6734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-29</th>\n",
       "      <td>15015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-31</th>\n",
       "      <td>24205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-31</th>\n",
       "      <td>32246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "2016-01-29    406\n",
       "2016-04-29   6734\n",
       "2016-07-29  15015\n",
       "2016-10-31  24205\n",
       "2017-01-31  32246"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.resample(\"3BM\").sum().head()\n",
    "## 0\n",
    "## 2016-01-29 406\n",
    "## 2016-04-29 6734\n",
    "## 2016-07-29 15015\n",
    "## 2016-10-31 24205\n",
    "## 2017-01-31 32246"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving window"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moving window functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/amzn.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\GIT-repository\\github-python-econometrics\\python-econometrics\\05-Applications.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GIT-repository/github-python-econometrics/python-econometrics/05-Applications.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Rolling mean\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GIT-repository/github-python-econometrics/python-econometrics/05-Applications.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/GIT-repository/github-python-econometrics/python-econometrics/05-Applications.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m amazon \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39mdata/amzn.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GIT-repository/github-python-econometrics/python-econometrics/05-Applications.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                      index_col\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GIT-repository/github-python-econometrics/python-econometrics/05-Applications.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                      parse_dates\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)[\u001b[39m\"\u001b[39m\u001b[39mAdj Close\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GIT-repository/github-python-econometrics/python-econometrics/05-Applications.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m fig \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m16\u001b[39m, \u001b[39m8\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GIT-repository/github-python-econometrics/python-econometrics/05-Applications.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m ax \u001b[39m=\u001b[39m fig\u001b[39m.\u001b[39madd_subplot(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Caíque Miranda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Caíque Miranda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\Caíque Miranda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Caíque Miranda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 934\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\Caíque Miranda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1218\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1215\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1218\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1219\u001b[0m     f,\n\u001b[0;32m   1220\u001b[0m     mode,\n\u001b[0;32m   1221\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1222\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1223\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1224\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1225\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1226\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1227\u001b[0m )\n\u001b[0;32m   1228\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1229\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Caíque Miranda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    782\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    785\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 786\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    787\u001b[0m             handle,\n\u001b[0;32m    788\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    789\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    790\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    791\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    792\u001b[0m         )\n\u001b[0;32m    793\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    794\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    795\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/amzn.csv'"
     ]
    }
   ],
   "source": [
    "# Rolling mean\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "amazon = pd.read_csv(\"data/amzn.csv\", \n",
    "                     index_col=0,\n",
    "                     parse_dates=True)[\"Adj Close\"]\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.set_ylabel(\"price\")\n",
    "\n",
    "amazon.plot(ax=ax, label=\"Amazon\")\n",
    "amazon.rolling(window=20).mean().plot(ax=ax, label=\"Rolling mean\")\n",
    "\n",
    "ax.legend(loc=\"best\")\n",
    "ax.set_title(\"Amazon price and rolling mean\", fontsize=25)\n",
    "\n",
    "fig.savefig(\"data/amzn.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "pfizer = pd.read_csv(\"data/pfe.csv\", \n",
    "                     index_col=0,\n",
    "                     parse_dates=True)[\"Adj Close\"]\n",
    "\n",
    "pg = pd.read_csv(\"data/pg.csv\", \n",
    "                 index_col=0,\n",
    "                 parse_dates=True)[\"Adj Close\"]\n",
    "\n",
    "prices = pd.DataFrame(index=amazon.index)\n",
    "\n",
    "prices[\"amazon\"] = pd.DataFrame(amazon)\n",
    "prices[\"pfizer\"] = pd.DataFrame(pfizer)\n",
    "prices[\"pg\"] = pd.DataFrame(pg)\n",
    "\n",
    "prices_std = prices.rolling(window=20).std()\n",
    "prices_std.plot(ax=ax)\n",
    "\n",
    "ax.set_title(\"Standard deviation\", fontsize=25)\n",
    "\n",
    "fig.savefig(\"data/std.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logarithmic standard deviation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "prices_std.plot(ax=ax, logy=True)\n",
    "\n",
    "ax.set_title(\"Logarithmic standard deviation\", fontsize=25)\n",
    "\n",
    "fig.savefig(\"data/std_log.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponentially weighted functions\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "amazon.rolling(window=40).mean().plot(ax=ax, label=\"Rolling mean\")\n",
    "amazon.ewm(span=40).mean().plot(ax=ax, \n",
    "                                label=\"Exp mean\",\n",
    "                                linestyle=\"--\", \n",
    "                                color=\"red\")\n",
    "\n",
    "amazon.plot(ax=ax, label=\"Amazon price\")\n",
    "\n",
    "ax.legend(loc=\"best\")\n",
    "ax.set_title(\"Exponentially weighted functions\", fontsize=25)\n",
    "\n",
    "fig.savefig(\"data/mean.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage change\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "returns = prices.pct_change()\n",
    "\n",
    "returns.head()\n",
    "## amazon pfizer pg\n",
    "## Date\n",
    "## 2017-02-23 NaN NaN NaN\n",
    "## 2017-02-24 -0.008155 0.005872 -0.000878\n",
    "## 2017-02-27 0.004023 0.000584 -0.001757\n",
    "## 2017-02-28 -0.004242 -0.004668 0.001980\n",
    "## 2017-03-01 0.009514 0.008792 0.006479\n",
    "returns.plot(ax=ax)\n",
    "\n",
    "ax.set_title(\"Returns\", fontsize=25)\n",
    "\n",
    "fig.savefig(\"data/returns.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "DJI = pd.read_csv(\"data/dji.csv\", \n",
    "                  index_col=0,\n",
    "                  parse_dates=True)[\"Adj Close\"]\n",
    "\n",
    "DJI_ret = DJI.pct_change()\n",
    "corr = returns.rolling(window=20).corr(DJI_ret)\n",
    "corr.plot(ax=ax)\n",
    "\n",
    "ax.grid()\n",
    "ax.set_title(\"20 days correlation\", fontsize=25)\n",
    "\n",
    "fig.savefig(\"data/corr.pdf\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Financial applications"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cumulative returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ret_index = (1 + returns).cumprod()\n",
    "stocks = [\"amazon\", \"pfizer\", \"pg\"]\n",
    "\n",
    "for i in stocks:\n",
    "    ret_index[i][0] = 1\n",
    "\n",
    "ret_index.tail()\n",
    "## amazon pfizer pg\n",
    "## Date\n",
    "## 2018-02-15 1.715298 1.088693 0.932322\n",
    "## 2018-02-16 1.699961 1.105461 0.934471\n",
    "## 2018-02-20 1.723031 1.097840 0.920217\n",
    "## 2018-02-21 1.740128 1.090218 0.907772\n",
    "## 2018-02-22 1.742968 1.090218 0.914560\n",
    "\n",
    "ret_index.plot(ax=ax)\n",
    "ax.set_title(\"Cumulative returns\", fontsize=25)\n",
    "\n",
    "fig.savefig(\"data/cumret.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly returns\n",
    "\n",
    "returns_m = ret_index.resample(\"BM\").last().pct_change()\n",
    "returns_m.head()\n",
    "## amazon pfizer pg\n",
    "## Date\n",
    "## 2017-02-28 NaN NaN NaN\n",
    "## 2017-03-31 0.049110 0.002638 -0.013396\n",
    "## 2017-04-28 0.043371 -0.008477 -0.020604\n",
    "## 2017-05-31 0.075276 -0.028124 0.008703\n",
    "## 2017-06-30 -0.026764 0.028790 -0.010671"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Volatility calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volatility\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "vola = returns.rolling(window=20).std() * np.sqrt(20)\n",
    "\n",
    "vola.plot(ax=ax)\n",
    "ax.set_title(\"Volatility\", fontsize=25)\n",
    "\n",
    "fig.savefig(\"data/vola.pdf\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe\n",
    "\n",
    "prices.describe()\n",
    "## amazon pfizer pg\n",
    "## count 252.000000 251.000000 252.000000\n",
    "## mean 1044.521903 33.892665 87.934304\n",
    "## std 158.041844 1.694680 2.728659\n",
    "## min 843.200012 30.872143 79.919998\n",
    "## 25% 953.567474 32.593733 86.241475\n",
    "## 50% 988.680023 33.147469 87.863598\n",
    "## 75% 1136.952484 35.331834 90.363035\n",
    "## max 1485.339966 38.661823 92.988976"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Return analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i].set_title(stocks[i])\n",
    "\n",
    "returns[stocks[i]].hist(ax=ax[i], bins=50)\n",
    "\n",
    "fig.savefig(\"data/return_hist.pdf\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordinary Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression data\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "Y = np.array(amazon.loc[\"2018-1-1\":\"2018-1-15\"].tolist())\n",
    "X = np.arange(len(Y))\n",
    "\n",
    "ax.scatter(x=X, y=Y, marker=\"o\", color=\"red\")\n",
    "\n",
    "fig.savefig(\"data/reg_data.pdf\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordinary Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression\n",
    "\n",
    "X_reg = sm.add_constant(X)\n",
    "\n",
    "res = sm.OLS(Y, X_reg).fit()\n",
    "\n",
    "b, a = res.params\n",
    "\n",
    "ax.plot(X, a * X + b)\n",
    "\n",
    "fig.savefig(\"data/ols.pdf\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Newton-Raphson implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Newton-Raphson requirements\n",
    "\n",
    "def f(x):\n",
    "    return 3 * x**3 + 3 * x**2 - 5 * x\n",
    "\n",
    "def df(x):\n",
    "    return 9 * x**2 + 6 * x - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Newton-Raphson\n",
    "\n",
    "def newton_raphson(fun, dfun, x0, e):\n",
    "    delta = abs(fun(x0))\n",
    "\n",
    "    while delta > e:\n",
    "        ax.scatter(x0, f(x0), color=\"red\", s=80)\n",
    "        x0 = x0 - fun(x0) / dfun(x0)\n",
    "        delta = abs(fun(x0))\n",
    "\n",
    "    ax.scatter(x0, f(x0), color=\"black\", s=80)\n",
    "    return(x0)\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "x = np.arange(-1.5, 1.7, 0.001)\n",
    "\n",
    "ax.plot(x, f(x))\n",
    "ax.grid()\n",
    "\n",
    "x_root = newton_raphson(f, df, -1, 0.1)\n",
    "\n",
    "fig.savefig(\"data/newton_raphson_root.pdf\")\n",
    "\n",
    "print(f\"Root at: {x_root:.4f}\")\n",
    "## Root at: 0.8878"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddf(x):\n",
    "    return 18 * x + 6\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "x = np.arange(-1.5, 1.7, 0.001)\n",
    "\n",
    "ax.plot(x, f(x))\n",
    "ax.grid()\n",
    "\n",
    "x_opt = newton_raphson(df, ddf, 1, 0.1)\n",
    "\n",
    "fig.savefig(\"data/newton_raphson_optimum.pdf\")\n",
    "\n",
    "print(f\"Minimum at: {x_opt:.4f}\")\n",
    "## Minimum at: 0.4886"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization with SciPy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The minimize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import minimize\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D optimization using minimize\n",
    "\n",
    "def f(x):\n",
    "    return (x - 4)**2 + 3\n",
    "\n",
    "x0 = [1] # the initial guess\n",
    "\n",
    "result = minimize(f, x0)\n",
    "\n",
    "result\n",
    "## fun: 3.0000000000000036\n",
    "## hess_inv: array([[0.49999999]])\n",
    "## jac: array([-8.94069672e-08])\n",
    "## message: 'Optimization terminated successfully.'\n",
    "## nfev: 6\n",
    "## nit: 2\n",
    "## njev: 3\n",
    "## status: 0\n",
    "## success: True\n",
    "## x: array([3.99999994])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D optimization using minimize\n",
    "\n",
    "min_y = result.fun # get minimum of the function f\n",
    "min_x = result.x # get the x value of the minimum\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "x = np.arange(1, 7, 0.001)\n",
    "\n",
    "ax.plot(x, f(x))\n",
    "ax.scatter(min_x, min_y, color=\"red\", s=120)\n",
    "\n",
    "fig.savefig(\"data/minimize_1D.pdf\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D optimization using minimize\n",
    "\n",
    "def f(x):\n",
    "    return (x[0] - 1)**2 + (x[1] - 2.5)**2\n",
    "\n",
    "x0 = [0, 0] # the initial guess\n",
    "\n",
    "result = minimize(f, x0)\n",
    "\n",
    "result\n",
    "## fun: 1.968344227868139e-15\n",
    "## hess_inv: array([[ 0.93103448, -0.1724138 ],\n",
    "## [-0.1724138 , 0.56896552]])\n",
    "## jac: array([-6.95567350e-08, 4.21085256e-08])\n",
    "## message: 'Optimization terminated successfully.'\n",
    "## nfev: 9\n",
    "## nit: 2\n",
    "## njev: 3\n",
    "## status: 0\n",
    "## success: True\n",
    "## x: array([0.99999996, 2.50000001])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of solver algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison\n",
    "\n",
    "def rosen(x):\n",
    "    return (1 - x[0])**2 + 100 * (x[1] - x[0]**2)**2\n",
    "\n",
    "x0 = [1.3, 0.4] # random initial guess\n",
    "\n",
    "res_1 = minimize(rosen, x0, method=\"Nelder-Mead\")\n",
    "res_2 = minimize(rosen, x0, method=\"Powell\")\n",
    "res_3 = minimize(rosen, x0, method=\"CG\")\n",
    "res_4 = minimize(rosen, x0, method=\"BFGS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison results\n",
    "\n",
    "# The perfect solution would be (1, 1)\n",
    "\n",
    "print(res_1.x)\n",
    "## array([1.00000287, 1.00000496])\n",
    "\n",
    "print(res_2.x)\n",
    "## array([1., 1.])\n",
    "\n",
    "print(res_3.x)\n",
    "## array([0.99999552, 0.99999104])\n",
    "\n",
    "print(res_4.x)\n",
    "## array([0.99999554, 0.99999108])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constrained optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tin can optimization\n",
    "\n",
    "def s(x):\n",
    "    r = x[0]\n",
    "    h = x[1]\n",
    "    return 2 * np.pi * r * (r + h)\n",
    "\n",
    "def v(x):\n",
    "    r = x[0]\n",
    "    h = x[1]\n",
    "    return np.pi * r**2 * h - 500 # as it is compared to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraints\n",
    "\n",
    "con = {\"type\": \"eq\", \"fun\": v}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constrained optimization result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tin can optimization\n",
    "\n",
    "x0 = [1, 1]\n",
    "\n",
    "result = minimize(s, x0, method=\"SLSQP\", constraints=con)\n",
    "\n",
    "print(result)\n",
    "## fun: 348.7342054449393\n",
    "## jac: array([108.10270309, 27.02567673])\n",
    "## message: 'Optimization terminated successfully'\n",
    "## nfev: 29\n",
    "## nit: 9\n",
    "## njev: 9\n",
    "## status: 0\n",
    "## success: True\n",
    "## x: array([4.3012702 , 8.60253961])\n",
    "\n",
    "x = result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tin can optimization result\n",
    "\n",
    "r, h = x\n",
    "\n",
    "print(r)\n",
    "## 4.301270202292404\n",
    "\n",
    "print(h)\n",
    "## 8.60253960537927\n",
    "\n",
    "print(np.pi * r**2 * h)\n",
    "## 499.99999998290457\n",
    "\n",
    "print(s(x))\n",
    "## 348.7342054449393"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a \"Caique Miranda\" -gu \"caiquemiranda\" -iv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74af3d2f25f1e46ebd2903d59225d79e4675ec224d56c01fc30cd168c2010d53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
